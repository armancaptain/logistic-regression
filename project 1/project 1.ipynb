{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUIqIT_djKMu"
      },
      "source": [
        "#1- import liberys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F0qZ6SpjPg9"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "from skimage.transform import resize\n",
        "from PIL import Image, ImageTk\n",
        "import imageio\n",
        "from lr_utils import load_dataset\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mdcrR5jjfiP"
      },
      "source": [
        "# 2- Load and clean the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A_lKecXjoNW"
      },
      "source": [
        "#----------------------Load and clean the dataset----------------------------------------\n",
        "\n",
        "#Load the data (cat/not cat datasets)\n",
        "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
        "\n",
        "#Lets visualize the train set\n",
        "print(train_set_x_orig)\n",
        "print(train_set_y)\n",
        "print(classes)\n",
        "\n",
        "#Example of image to test and see if the import worked\n",
        "#index = 20\n",
        "#plt.imshow(train_set_x_orig[index])\n",
        "#print(\"y = \" + str(train_set_y[:,index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:,index])].decode(\"utf-8\") + \"' picture.\")\n",
        "\n",
        "#Lets get some basic data about our image numpy arrays\n",
        "m_train = train_set_x_orig.shape[0]\n",
        "m_test = test_set_x_orig.shape[0]\n",
        "num_px = train_set_x_orig.shape[1]\n",
        "\n",
        "print(\"Number of training examples: m_train = \" + str(m_train))\n",
        "print(\"Number of test examples: m_test = \" + str(m_test))\n",
        "print(\"Height/Width of each image: num_px = \" + str(num_px))\n",
        "print(\"Each image is of size: (\"+ str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
        "print(\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
        "print(\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print(\"test_set_x shape : \" + str(test_set_x_orig.shape))\n",
        "print(\"test_set_y shape: \"+ str(test_set_y.shape))\n",
        "\n",
        "#Will now flatten the numpy array from (num_px, num_px, 3) to (num_px*num_px*3, 1) \n",
        "#this will make it easier for us so that each image in one numpy array column\n",
        "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
        "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
        "\n",
        "print(\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
        "print(\"train_set_y shape: \" + str(train_set_y.shape))\n",
        "print(\"test_set_x_flatten shape: \"+ str(test_set_x_flatten.shape))\n",
        "print(\"test_set_y shape: \"+ str(test_set_y.shape))\n",
        "\n",
        "#Standardize the dataset for images by dividing each by 255\n",
        "train_set_x = train_set_x_flatten/255\n",
        "test_set_x = test_set_x_flatten/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e33FWU-fjvN3"
      },
      "source": [
        "# 3- Build the Logisitic Regression framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzLujth1j12e"
      },
      "source": [
        "#--------------------------Build the Logisitic Regression framework-------------------------\n",
        "\n",
        "#We will be using a sigmoid function for our Activation, in Neural Networks most are not ReLU due to speed of calc\n",
        "\n",
        "def sigmoid(z):\n",
        "    s = 1/(1+np.exp(-(z)))\n",
        "    return s\n",
        "\n",
        "#Create function to set both w and b to 0 to start with\n",
        "def initialize_with_zeros(dim):\n",
        "    w = np.zeros((dim,1))\n",
        "    b = 0\n",
        "    return w,b\n",
        "\n",
        "#Create a function that calculates the current SSE\n",
        "def propagate(w, b, X, Y):\n",
        "    m = X.shape[1]\n",
        "    A = sigmoid(np.dot(w.T,X)+b)\n",
        "    cost = -1/m * np.sum(Y*np.log(A)+(1-Y)*np.log(1-A))\n",
        "    dw = (1/m) * (np.dot(X,(A-Y).T))\n",
        "    db = (1/m) * (np.sum(A-Y))\n",
        "    \n",
        "    cost = np.squeeze(cost)\n",
        "    \n",
        "    grads = {\"dw\": dw, \"db\": db}\n",
        "    \n",
        "    return grads, cost\n",
        "\n",
        "#Create a function that moves the estimates around and calculates the SSE to find optimal w and b\n",
        "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
        "    costs = []\n",
        "    for i in range(num_iterations):\n",
        "        grads, cost = propagate(w,b,X,Y)\n",
        "        dw = grads[\"dw\"]\n",
        "        db = grads[\"db\"]\n",
        "        w = w-learning_rate*dw\n",
        "        b = b-learning_rate*db\n",
        "        if i % 100 == 0:\n",
        "            costs.append(cost)\n",
        "        if print_cost and i % 100 == 0:\n",
        "            print(\"Cost after iteration %i: %f\" %(i, cost))\n",
        "    \n",
        "    params = {\"w\":w,\"b\":b}\n",
        "    grads = {\"dw\":dw,\"db\":db}\n",
        "    \n",
        "    return params, grads, costs\n",
        "\n",
        "def predict(w, b, X):\n",
        "    m = X.shape[1]\n",
        "    Y_prediction = np.zeros((1,m))\n",
        "    w = w.reshape(X.shape[0],1)\n",
        "    A = sigmoid(np.dot(w.T,X)+b)\n",
        "    for i in range(A.shape[1]):\n",
        "        if A[0,i] <= 0.5:\n",
        "            Y_prediction[0,i] = 0\n",
        "        else:\n",
        "            Y_prediction[0,i] = 1\n",
        "            \n",
        "    return Y_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mnj3htRwj7dG"
      },
      "source": [
        "# 4- Merge all the components in to a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqGaG792kATG"
      },
      "source": [
        "#----------------------Merge all the components in to a model----------------------------\n",
        "\n",
        "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5, print_cost = False):\n",
        "    global D\n",
        "    #Initialize paramters with 0\n",
        "    w,b = initialize_with_zeros(X_train.shape[0])\n",
        "    #Perform Gradient Descent\n",
        "    parameters, grads, costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n",
        "    #Retrieve parameters w and b from dictionary \"parameters\"\n",
        "    w = parameters[\"w\"]\n",
        "    b = parameters[\"b\"]\n",
        "    #Predict test/train set examples\n",
        "    Y_prediction_test = predict(w,b,X_test)\n",
        "    Y_prediction_train = predict(w,b,X_train)\n",
        "    #Print train/test errors\n",
        "    print(\"train accuracy: {} %\".format(100-np.mean(np.abs(Y_prediction_train-Y_train))*100))\n",
        "    print(\"test accuracy: {} %\".format(100-np.mean(np.abs(Y_prediction_test-Y_test))*100))\n",
        "    \n",
        "    d = {\"costs\": costs,\n",
        "         \"Y_prediction_test\": Y_prediction_test,\n",
        "         \"Y_prediction_train\": Y_prediction_train,\n",
        "         \"w\":w,\n",
        "         \"b\":b,\n",
        "         \"learning_rate\": learning_rate,\n",
        "         \"num_iterations\": num_iterations}\n",
        "    D = d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vchNF7cZkDb-"
      },
      "source": [
        "# 5- Test on our own image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBUXxGONkJBm"
      },
      "source": [
        "#----------------------Test on our own image----------------------------------------\n",
        "\n",
        "def run_on_own_image(my_image):\n",
        "    fname = my_image\n",
        "    image = np.array(imageio.imread(fname))\n",
        "    my_image = resize(image, output_shape=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
        "    my_predicted_image = predict(D[\"w\"], D[\"b\"],my_image)\n",
        "    \n",
        "    #plt.imshow(image)\n",
        "    print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicted a \\\"\" \n",
        "      + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") + \"\\\" picture.\")\n",
        "    labelText = tk.Label(text=\"Your algorithm predicted a \" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\"))\n",
        "    labelText.text = \"Your algorithm predicted a \" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\")\n",
        "    labelText.pack()    \n",
        "    img = Image.open(fname)\n",
        "    img = img.resize((300,300), Image.ANTIALIAS)\n",
        "    photo = ImageTk.PhotoImage(img)\n",
        "    label = tk.Label(image=photo)\n",
        "    label.image = photo\n",
        "    label.pack()\n",
        "\n",
        "def choose_file():\n",
        "    global fileNameGlobal\n",
        "    filename = askopenfilename()\n",
        "    fileNameGlobal = filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSsCoK0Hka-v"
      },
      "source": [
        "# 6- Test on our own image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kMJhfUTkmQO"
      },
      "source": [
        "#----------------------Test on our own image----------------------------------------\n",
        "\n",
        "def run_on_own_image(my_image):\n",
        "    fname = my_image\n",
        "    image = np.array(imageio.imread(fname))\n",
        "    my_image = resize(image, output_shape=(num_px,num_px)).reshape((1, num_px*num_px*3)).T\n",
        "    my_predicted_image = predict(D[\"w\"], D[\"b\"],my_image)\n",
        "    \n",
        "    #plt.imshow(image)\n",
        "    print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicted a \\\"\" \n",
        "      + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") + \"\\\" picture.\")\n",
        "    labelText = tk.Label(text=\"Your algorithm predicted a \" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\"))\n",
        "    labelText.text = \"Your algorithm predicted a \" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\")\n",
        "    labelText.pack()    \n",
        "    img = Image.open(fname)\n",
        "    img = img.resize((300,300), Image.ANTIALIAS)\n",
        "    photo = ImageTk.PhotoImage(img)\n",
        "    label = tk.Label(image=photo)\n",
        "    label.image = photo\n",
        "    label.pack()\n",
        "\n",
        "def choose_file():\n",
        "    global fileNameGlobal\n",
        "    filename = askopenfilename()\n",
        "    fileNameGlobal = filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rw9vXysXlRov"
      },
      "source": [
        "# 7- Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a3Asuu2lTDf"
      },
      "source": [
        "#--------------------------Run the model------------------------------------------------\n",
        "\n",
        "#d = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.005, print_cost=True)\n",
        "import tkinter as tk\n",
        "from tkinter.filedialog import askopenfilename\n",
        "\n",
        "master = tk.Tk()\n",
        "\n",
        "trainButton = tk.Button(master, text=\"Train Model\", command = lambda: model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.005, print_cost=True))\n",
        "trainButton.pack()\n",
        "\n",
        "fileButton = tk.Button(master, text=\"Choose your own file\", command=choose_file)\n",
        "fileButton.pack()\n",
        "\n",
        "ownImageButton = tk.Button(master, text=\"Test Own Image\", command = lambda: run_on_own_image(fileNameGlobal))\n",
        "ownImageButton.pack()\n",
        "\n",
        "tk.mainloop()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}